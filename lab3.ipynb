{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab #3 \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/basic-operations-workshop/blob/main/lab3.ipynb)\n",
    "1. Install dependencies\n",
    "2. Create a pinecone index \n",
    "3. Load public image dataset(fashion-mnist) and create vector embeddings from the dataset\n",
    "4. Create a local parquet backup of your image embeddings\n",
    "5. Insert the fashion-mnist embeddings into Pinecone\n",
    "6. Run a nearest neighbor search on a sample image that is not in the training dataset\n",
    "7. Run a nearest neighbor search on 100 random test images that are not in the training dataset\n",
    "8. Run a load test script to simulate 10 concurrent users querying the index\n",
    "9. TEARDOWN: Delete the index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install Pinecone client \n",
    "Use the following shell command to install Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: absl-py 1.4.0\n",
      "Uninstalling absl-py-1.4.0:\n",
      "  Successfully uninstalled absl-py-1.4.0\n",
      "Found existing installation: aiohttp 3.8.5\n",
      "Uninstalling aiohttp-3.8.5:\n",
      "  Successfully uninstalled aiohttp-3.8.5\n",
      "Found existing installation: aiosignal 1.3.1\n",
      "Uninstalling aiosignal-1.3.1:\n",
      "  Successfully uninstalled aiosignal-1.3.1\n",
      "Found existing installation: appnope 0.1.3\n",
      "Uninstalling appnope-0.1.3:\n",
      "  Successfully uninstalled appnope-0.1.3\n",
      "Found existing installation: asttokens 2.2.1\n",
      "Uninstalling asttokens-2.2.1:\n",
      "  Successfully uninstalled asttokens-2.2.1\n",
      "Found existing installation: astunparse 1.6.3\n",
      "Uninstalling astunparse-1.6.3:\n",
      "  Successfully uninstalled astunparse-1.6.3\n",
      "Found existing installation: async-timeout 4.0.2\n",
      "Uninstalling async-timeout-4.0.2:\n",
      "  Successfully uninstalled async-timeout-4.0.2\n",
      "Found existing installation: attrs 23.1.0\n",
      "Uninstalling attrs-23.1.0:\n",
      "  Successfully uninstalled attrs-23.1.0\n",
      "Found existing installation: backcall 0.2.0\n",
      "Uninstalling backcall-0.2.0:\n",
      "  Successfully uninstalled backcall-0.2.0\n",
      "Found existing installation: blinker 1.6.2\n",
      "Uninstalling blinker-1.6.2:\n",
      "  Successfully uninstalled blinker-1.6.2\n",
      "Found existing installation: Brotli 1.0.9\n",
      "Uninstalling Brotli-1.0.9:\n",
      "  Successfully uninstalled Brotli-1.0.9\n",
      "Found existing installation: cachetools 5.3.1\n",
      "Uninstalling cachetools-5.3.1:\n",
      "  Successfully uninstalled cachetools-5.3.1\n",
      "Found existing installation: certifi 2023.7.22\n",
      "Uninstalling certifi-2023.7.22:\n",
      "  Successfully uninstalled certifi-2023.7.22\n",
      "Found existing installation: charset-normalizer 3.2.0\n",
      "Uninstalling charset-normalizer-3.2.0:\n",
      "  Successfully uninstalled charset-normalizer-3.2.0\n",
      "Found existing installation: click 8.1.6\n",
      "Uninstalling click-8.1.6:\n",
      "  Successfully uninstalled click-8.1.6\n",
      "Found existing installation: clip 1.0\n",
      "Uninstalling clip-1.0:\n",
      "  Successfully uninstalled clip-1.0\n",
      "\u001b[31mERROR: Invalid requirement: '@'\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Invalid requirement: 'git+https://github.com/openai/clip.git@a1d071733d7111c9c014f024669f959182114e33' ignored - the uninstall command expects named requirements.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: You must give at least one requirement to uninstall (see \"pip help uninstall\")\u001b[0m\u001b[31m\n",
      "\u001b[0mFound existing installation: comm 0.1.4\n",
      "Uninstalling comm-0.1.4:\n",
      "  Successfully uninstalled comm-0.1.4\n",
      "Found existing installation: ConfigArgParse 1.7\n",
      "Uninstalling ConfigArgParse-1.7:\n",
      "  Successfully uninstalled ConfigArgParse-1.7\n",
      "Found existing installation: datasets 2.14.3\n",
      "Uninstalling datasets-2.14.3:\n",
      "  Successfully uninstalled datasets-2.14.3\n",
      "Found existing installation: debugpy 1.6.8\n",
      "Uninstalling debugpy-1.6.8:\n",
      "  Successfully uninstalled debugpy-1.6.8\n",
      "Found existing installation: decorator 5.1.1\n",
      "Uninstalling decorator-5.1.1:\n",
      "  Successfully uninstalled decorator-5.1.1\n",
      "Found existing installation: dill 0.3.7\n",
      "Uninstalling dill-0.3.7:\n",
      "  Successfully uninstalled dill-0.3.7\n",
      "Found existing installation: dnspython 2.4.1\n",
      "Uninstalling dnspython-2.4.1:\n",
      "  Successfully uninstalled dnspython-2.4.1\n",
      "Found existing installation: executing 1.2.0\n",
      "Uninstalling executing-1.2.0:\n",
      "  Successfully uninstalled executing-1.2.0\n",
      "Found existing installation: filelock 3.12.2\n",
      "Uninstalling filelock-3.12.2:\n",
      "  Successfully uninstalled filelock-3.12.2\n",
      "Found existing installation: Flask 2.3.2\n",
      "Uninstalling Flask-2.3.2:\n",
      "  Successfully uninstalled Flask-2.3.2\n",
      "Found existing installation: Flask-BasicAuth 0.2.0\n",
      "Uninstalling Flask-BasicAuth-0.2.0:\n",
      "  Successfully uninstalled Flask-BasicAuth-0.2.0\n",
      "Found existing installation: Flask-Cors 4.0.0\n",
      "Uninstalling Flask-Cors-4.0.0:\n",
      "  Successfully uninstalled Flask-Cors-4.0.0\n",
      "Found existing installation: flatbuffers 23.5.26\n",
      "Uninstalling flatbuffers-23.5.26:\n",
      "  Successfully uninstalled flatbuffers-23.5.26\n",
      "Found existing installation: frozenlist 1.4.0\n",
      "Uninstalling frozenlist-1.4.0:\n",
      "  Successfully uninstalled frozenlist-1.4.0\n",
      "Found existing installation: fsspec 2023.6.0\n",
      "Uninstalling fsspec-2023.6.0:\n",
      "  Successfully uninstalled fsspec-2023.6.0\n",
      "Found existing installation: ftfy 6.1.1\n",
      "Uninstalling ftfy-6.1.1:\n",
      "  Successfully uninstalled ftfy-6.1.1\n",
      "Found existing installation: gast 0.4.0\n",
      "Uninstalling gast-0.4.0:\n",
      "  Successfully uninstalled gast-0.4.0\n",
      "Found existing installation: gevent 23.7.0\n",
      "Uninstalling gevent-23.7.0:\n",
      "  Successfully uninstalled gevent-23.7.0\n",
      "Found existing installation: geventhttpclient 2.0.9\n",
      "Uninstalling geventhttpclient-2.0.9:\n",
      "  Successfully uninstalled geventhttpclient-2.0.9\n",
      "Found existing installation: google-auth 2.22.0\n",
      "Uninstalling google-auth-2.22.0:\n",
      "  Successfully uninstalled google-auth-2.22.0\n",
      "Found existing installation: google-auth-oauthlib 1.0.0\n",
      "Uninstalling google-auth-oauthlib-1.0.0:\n",
      "  Successfully uninstalled google-auth-oauthlib-1.0.0\n",
      "Found existing installation: google-pasta 0.2.0\n",
      "Uninstalling google-pasta-0.2.0:\n",
      "  Successfully uninstalled google-pasta-0.2.0\n",
      "Found existing installation: greenlet 2.0.2\n",
      "Uninstalling greenlet-2.0.2:\n",
      "  Successfully uninstalled greenlet-2.0.2\n",
      "Found existing installation: grpcio 1.56.2\n",
      "Uninstalling grpcio-1.56.2:\n",
      "  Successfully uninstalled grpcio-1.56.2\n",
      "Found existing installation: h5py 3.9.0\n",
      "Uninstalling h5py-3.9.0:\n",
      "  Successfully uninstalled h5py-3.9.0\n",
      "Found existing installation: huggingface-hub 0.16.4\n",
      "Uninstalling huggingface-hub-0.16.4:\n",
      "  Successfully uninstalled huggingface-hub-0.16.4\n",
      "Found existing installation: idna 3.4\n",
      "Uninstalling idna-3.4:\n",
      "  Successfully uninstalled idna-3.4\n",
      "Found existing installation: ipykernel 6.25.0\n",
      "Uninstalling ipykernel-6.25.0:\n",
      "  Successfully uninstalled ipykernel-6.25.0\n",
      "Found existing installation: ipython 8.14.0\n",
      "Uninstalling ipython-8.14.0:\n",
      "  Successfully uninstalled ipython-8.14.0\n",
      "Found existing installation: itsdangerous 2.1.2\n",
      "Uninstalling itsdangerous-2.1.2:\n",
      "  Successfully uninstalled itsdangerous-2.1.2\n",
      "Found existing installation: jedi 0.19.0\n",
      "Uninstalling jedi-0.19.0:\n",
      "  Successfully uninstalled jedi-0.19.0\n",
      "Found existing installation: Jinja2 3.1.2\n",
      "Uninstalling Jinja2-3.1.2:\n",
      "  Successfully uninstalled Jinja2-3.1.2\n",
      "Found existing installation: jupyter_client 8.3.0\n",
      "Uninstalling jupyter_client-8.3.0:\n",
      "  Successfully uninstalled jupyter_client-8.3.0\n",
      "Found existing installation: jupyter_core 5.3.1\n",
      "Uninstalling jupyter_core-5.3.1:\n",
      "  Successfully uninstalled jupyter_core-5.3.1\n",
      "Found existing installation: keras 2.13.1\n",
      "Uninstalling keras-2.13.1:\n",
      "  Successfully uninstalled keras-2.13.1\n",
      "Found existing installation: libclang 16.0.6\n",
      "Uninstalling libclang-16.0.6:\n",
      "  Successfully uninstalled libclang-16.0.6\n",
      "Found existing installation: locust 2.15.1\n",
      "Uninstalling locust-2.15.1:\n",
      "  Successfully uninstalled locust-2.15.1\n",
      "Found existing installation: loguru 0.7.0\n",
      "Uninstalling loguru-0.7.0:\n",
      "  Successfully uninstalled loguru-0.7.0\n",
      "Found existing installation: Markdown 3.4.4\n",
      "Uninstalling Markdown-3.4.4:\n",
      "  Successfully uninstalled Markdown-3.4.4\n",
      "Found existing installation: MarkupSafe 2.1.3\n",
      "Uninstalling MarkupSafe-2.1.3:\n",
      "  Successfully uninstalled MarkupSafe-2.1.3\n",
      "Found existing installation: matplotlib-inline 0.1.6\n",
      "Uninstalling matplotlib-inline-0.1.6:\n",
      "  Successfully uninstalled matplotlib-inline-0.1.6\n",
      "Found existing installation: mpmath 1.3.0\n",
      "Uninstalling mpmath-1.3.0:\n",
      "  Successfully uninstalled mpmath-1.3.0\n",
      "Found existing installation: msgpack 1.0.5\n",
      "Uninstalling msgpack-1.0.5:\n",
      "  Successfully uninstalled msgpack-1.0.5\n",
      "Found existing installation: multidict 6.0.4\n",
      "Uninstalling multidict-6.0.4:\n",
      "  Successfully uninstalled multidict-6.0.4\n",
      "Found existing installation: multiprocess 0.70.15\n",
      "Uninstalling multiprocess-0.70.15:\n",
      "  Successfully uninstalled multiprocess-0.70.15\n",
      "Found existing installation: nest-asyncio 1.5.7\n",
      "Uninstalling nest-asyncio-1.5.7:\n",
      "  Successfully uninstalled nest-asyncio-1.5.7\n",
      "Found existing installation: networkx 3.1\n",
      "Uninstalling networkx-3.1:\n",
      "  Successfully uninstalled networkx-3.1\n",
      "Found existing installation: numpy 1.24.3\n",
      "Uninstalling numpy-1.24.3:\n",
      "  Successfully uninstalled numpy-1.24.3\n",
      "Found existing installation: oauthlib 3.2.2\n",
      "Uninstalling oauthlib-3.2.2:\n",
      "  Successfully uninstalled oauthlib-3.2.2\n",
      "Found existing installation: opt-einsum 3.3.0\n",
      "Uninstalling opt-einsum-3.3.0:\n",
      "  Successfully uninstalled opt-einsum-3.3.0\n",
      "Found existing installation: packaging 23.1\n",
      "Uninstalling packaging-23.1:\n",
      "  Successfully uninstalled packaging-23.1\n",
      "Found existing installation: pandas 2.0.3\n",
      "Uninstalling pandas-2.0.3:\n",
      "  Successfully uninstalled pandas-2.0.3\n",
      "Found existing installation: parso 0.8.3\n",
      "Uninstalling parso-0.8.3:\n",
      "  Successfully uninstalled parso-0.8.3\n",
      "Found existing installation: pexpect 4.8.0\n",
      "Uninstalling pexpect-4.8.0:\n",
      "  Successfully uninstalled pexpect-4.8.0\n",
      "Found existing installation: pickleshare 0.7.5\n",
      "Uninstalling pickleshare-0.7.5:\n",
      "  Successfully uninstalled pickleshare-0.7.5\n",
      "Found existing installation: Pillow 10.0.0\n",
      "Uninstalling Pillow-10.0.0:\n",
      "  Successfully uninstalled Pillow-10.0.0\n",
      "Found existing installation: pinecone-client 2.2.2\n",
      "Uninstalling pinecone-client-2.2.2:\n",
      "  Successfully uninstalled pinecone-client-2.2.2\n",
      "Found existing installation: platformdirs 3.10.0\n",
      "Uninstalling platformdirs-3.10.0:\n",
      "  Successfully uninstalled platformdirs-3.10.0\n",
      "Found existing installation: prompt-toolkit 3.0.39\n",
      "Uninstalling prompt-toolkit-3.0.39:\n",
      "  Successfully uninstalled prompt-toolkit-3.0.39\n",
      "Found existing installation: protobuf 4.23.4\n",
      "Uninstalling protobuf-4.23.4:\n",
      "  Successfully uninstalled protobuf-4.23.4\n",
      "Found existing installation: psutil 5.9.5\n",
      "Uninstalling psutil-5.9.5:\n",
      "  Successfully uninstalled psutil-5.9.5\n",
      "Found existing installation: ptyprocess 0.7.0\n",
      "Uninstalling ptyprocess-0.7.0:\n",
      "  Successfully uninstalled ptyprocess-0.7.0\n",
      "Found existing installation: pure-eval 0.2.2\n",
      "Uninstalling pure-eval-0.2.2:\n",
      "  Successfully uninstalled pure-eval-0.2.2\n",
      "Found existing installation: pyarrow 12.0.1\n",
      "Uninstalling pyarrow-12.0.1:\n",
      "  Successfully uninstalled pyarrow-12.0.1\n",
      "Found existing installation: pyasn1 0.5.0\n",
      "Uninstalling pyasn1-0.5.0:\n",
      "  Successfully uninstalled pyasn1-0.5.0\n",
      "Found existing installation: pyasn1-modules 0.3.0\n",
      "Uninstalling pyasn1-modules-0.3.0:\n",
      "  Successfully uninstalled pyasn1-modules-0.3.0\n",
      "Found existing installation: Pygments 2.15.1\n",
      "Uninstalling Pygments-2.15.1:\n",
      "  Successfully uninstalled Pygments-2.15.1\n",
      "Found existing installation: python-dateutil 2.8.2\n",
      "Uninstalling python-dateutil-2.8.2:\n",
      "  Successfully uninstalled python-dateutil-2.8.2\n",
      "Found existing installation: python-dotenv 1.0.0\n",
      "Uninstalling python-dotenv-1.0.0:\n",
      "  Successfully uninstalled python-dotenv-1.0.0\n",
      "Found existing installation: pytz 2023.3\n",
      "Uninstalling pytz-2023.3:\n",
      "  Successfully uninstalled pytz-2023.3\n",
      "Found existing installation: PyYAML 6.0.1\n",
      "Uninstalling PyYAML-6.0.1:\n",
      "  Successfully uninstalled PyYAML-6.0.1\n",
      "Found existing installation: pyzmq 25.1.0\n",
      "Uninstalling pyzmq-25.1.0:\n",
      "  Successfully uninstalled pyzmq-25.1.0\n",
      "Found existing installation: regex 2023.6.3\n",
      "Uninstalling regex-2023.6.3:\n",
      "  Successfully uninstalled regex-2023.6.3\n",
      "Found existing installation: requests 2.31.0\n",
      "Uninstalling requests-2.31.0:\n",
      "  Successfully uninstalled requests-2.31.0\n",
      "Found existing installation: requests-oauthlib 1.3.1\n",
      "Uninstalling requests-oauthlib-1.3.1:\n",
      "  Successfully uninstalled requests-oauthlib-1.3.1\n",
      "Found existing installation: roundrobin 0.0.4\n",
      "Uninstalling roundrobin-0.0.4:\n",
      "  Successfully uninstalled roundrobin-0.0.4\n",
      "Found existing installation: rsa 4.9\n",
      "Uninstalling rsa-4.9:\n",
      "  Successfully uninstalled rsa-4.9\n",
      "Found existing installation: six 1.16.0\n",
      "Uninstalling six-1.16.0:\n",
      "  Successfully uninstalled six-1.16.0\n",
      "Found existing installation: stack-data 0.6.2\n",
      "Uninstalling stack-data-0.6.2:\n",
      "  Successfully uninstalled stack-data-0.6.2\n",
      "Found existing installation: sympy 1.12\n",
      "Uninstalling sympy-1.12:\n",
      "  Successfully uninstalled sympy-1.12\n",
      "Found existing installation: tensorboard 2.13.0\n",
      "Uninstalling tensorboard-2.13.0:\n",
      "  Successfully uninstalled tensorboard-2.13.0\n",
      "Found existing installation: tensorboard-data-server 0.7.1\n",
      "Uninstalling tensorboard-data-server-0.7.1:\n",
      "  Successfully uninstalled tensorboard-data-server-0.7.1\n",
      "Found existing installation: tensorflow 2.13.0\n",
      "Uninstalling tensorflow-2.13.0:\n",
      "  Successfully uninstalled tensorflow-2.13.0\n",
      "Found existing installation: tensorflow-estimator 2.13.0\n",
      "Uninstalling tensorflow-estimator-2.13.0:\n",
      "  Successfully uninstalled tensorflow-estimator-2.13.0\n",
      "Found existing installation: tensorflow-macos 2.13.0\n",
      "Uninstalling tensorflow-macos-2.13.0:\n",
      "  Successfully uninstalled tensorflow-macos-2.13.0\n",
      "Found existing installation: termcolor 2.3.0\n",
      "Uninstalling termcolor-2.3.0:\n",
      "  Successfully uninstalled termcolor-2.3.0\n",
      "Found existing installation: torch 2.0.1\n",
      "Uninstalling torch-2.0.1:\n",
      "  Successfully uninstalled torch-2.0.1\n",
      "Found existing installation: torchvision 0.15.2\n",
      "Uninstalling torchvision-0.15.2:\n",
      "  Successfully uninstalled torchvision-0.15.2\n",
      "Found existing installation: tornado 6.3.2\n",
      "Uninstalling tornado-6.3.2:\n",
      "  Successfully uninstalled tornado-6.3.2\n",
      "Found existing installation: tqdm 4.65.0\n",
      "Uninstalling tqdm-4.65.0:\n",
      "  Successfully uninstalled tqdm-4.65.0\n",
      "Found existing installation: traitlets 5.9.0\n",
      "Uninstalling traitlets-5.9.0:\n",
      "  Successfully uninstalled traitlets-5.9.0\n",
      "Found existing installation: typing_extensions 4.5.0\n",
      "Uninstalling typing_extensions-4.5.0:\n",
      "  Successfully uninstalled typing_extensions-4.5.0\n",
      "Found existing installation: tzdata 2023.3\n",
      "Uninstalling tzdata-2023.3:\n",
      "  Successfully uninstalled tzdata-2023.3\n",
      "Found existing installation: urllib3 1.26.16\n",
      "Uninstalling urllib3-1.26.16:\n",
      "  Successfully uninstalled urllib3-1.26.16\n",
      "Found existing installation: wcwidth 0.2.6\n",
      "Uninstalling wcwidth-0.2.6:\n",
      "  Successfully uninstalled wcwidth-0.2.6\n",
      "Found existing installation: Werkzeug 2.3.6\n",
      "Uninstalling Werkzeug-2.3.6:\n",
      "  Successfully uninstalled Werkzeug-2.3.6\n",
      "Found existing installation: wrapt 1.15.0\n",
      "Uninstalling wrapt-1.15.0:\n",
      "  Successfully uninstalled wrapt-1.15.0\n",
      "Found existing installation: xxhash 3.3.0\n",
      "Uninstalling xxhash-3.3.0:\n",
      "  Successfully uninstalled xxhash-3.3.0\n",
      "Found existing installation: yarl 1.9.2\n",
      "Uninstalling yarl-1.9.2:\n",
      "  Successfully uninstalled yarl-1.9.2\n",
      "Found existing installation: zope.event 5.0\n",
      "Uninstalling zope.event-5.0:\n",
      "  Successfully uninstalled zope.event-5.0\n",
      "Found existing installation: zope.interface 6.0\n",
      "Uninstalling zope.interface-6.0:\n",
      "  Successfully uninstalled zope.interface-6.0\n",
      "Collecting git+https://github.com/openai/clip.git\n",
      "  Cloning https://github.com/openai/clip.git to /private/var/folders/n7/j7krsnmx3wl7_bjrwhx2z7ym0000gn/T/pip-req-build-mnd0eddq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/clip.git /private/var/folders/n7/j7krsnmx3wl7_bjrwhx2z7ym0000gn/T/pip-req-build-mnd0eddq\n",
      "  Resolved https://github.com/openai/clip.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pinecone-client[grpc]\n",
      "  Obtaining dependency information for pinecone-client[grpc] from https://files.pythonhosted.org/packages/98/17/3675b83dca0a032d2750bf04fbfdf78a6e46fa3056eefc2574cdd14661d9/pinecone_client-2.2.2-py3-none-any.whl.metadata\n",
      "  Using cached pinecone_client-2.2.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp311-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp311-cp311-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Collecting pillow\n",
      "  Obtaining dependency information for pillow from https://files.pythonhosted.org/packages/b7/ad/71982d18fd28ed1f93c31b8648f980ebdbdbcf7d8c9c9b4af59290914ce9/Pillow-10.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached Pillow-10.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting ftfy\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting regex\n",
      "  Obtaining dependency information for regex from https://files.pythonhosted.org/packages/f8/bc/01e6a5597904147d13c1a6dc16ec334b73cddb190b6b8f05fca2c0bfbe89/regex-2023.6.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached regex-2023.6.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/25/55/ec0d602cec473f3857ca82c9f2ddbd5b8c4d1139debbf06e19aaff29f973/datasets-2.14.3-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.14.3-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting locust\n",
      "  Using cached locust-2.15.1-py3-none-any.whl (826 kB)\n",
      "Collecting requests>=2.19.0 (from pinecone-client[grpc])\n",
      "  Obtaining dependency information for requests>=2.19.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyyaml>=5.4 (from pinecone-client[grpc])\n",
      "  Obtaining dependency information for pyyaml>=5.4 from https://files.pythonhosted.org/packages/28/09/55f715ddbf95a054b764b547f617e22f1d5e45d83905660e9a088078fe67/PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting loguru>=0.5.0 (from pinecone-client[grpc])\n",
      "  Using cached loguru-0.7.0-py3-none-any.whl (59 kB)\n",
      "Collecting typing-extensions>=3.7.4 (from pinecone-client[grpc])\n",
      "  Obtaining dependency information for typing-extensions>=3.7.4 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting dnspython>=2.0.0 (from pinecone-client[grpc])\n",
      "  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/71/30/deee2ffb94194437c730a1c6230d9310ab5f73926a2549cdab91453616bb/dnspython-2.4.1-py3-none-any.whl.metadata\n",
      "  Using cached dnspython-2.4.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pinecone-client[grpc]) (2.8.2)\n",
      "Collecting urllib3>=1.21.1 (from pinecone-client[grpc])\n",
      "  Obtaining dependency information for urllib3>=1.21.1 from https://files.pythonhosted.org/packages/9b/81/62fd61001fa4b9d0df6e31d47ff49cfa9de4af03adecf339c7bc30656b37/urllib3-2.0.4-py3-none-any.whl.metadata\n",
      "  Using cached urllib3-2.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting numpy>=1.22.0 (from pinecone-client[grpc])\n",
      "  Obtaining dependency information for numpy>=1.22.0 from https://files.pythonhosted.org/packages/86/a1/b8ef999c32f26a97b5f714887e21f96c12ae99a38583a0a96e65283ac0a1/numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting grpcio>=1.44.0 (from pinecone-client[grpc])\n",
      "  Obtaining dependency information for grpcio>=1.44.0 from https://files.pythonhosted.org/packages/06/ed/4c7651a5af2628273a80ae55376f21c8e6fcababadfa0d6ec771aa02ee9b/grpcio-1.56.2-cp311-cp311-macosx_10_10_universal2.whl.metadata\n",
      "  Using cached grpcio-1.56.2-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting grpc-gateway-protoc-gen-openapiv2==0.1.0 (from pinecone-client[grpc])\n",
      "  Using cached grpc_gateway_protoc_gen_openapiv2-0.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting googleapis-common-protos>=1.53.0 (from pinecone-client[grpc])\n",
      "  Obtaining dependency information for googleapis-common-protos>=1.53.0 from https://files.pythonhosted.org/packages/a7/bc/416a1ffeba4dcd072bc10523dac9ed97f2e7fc4b760580e2bdbdc1e2afdd/googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting lz4>=3.1.3 (from pinecone-client[grpc])\n",
      "  Using cached lz4-4.3.2-cp311-cp311-macosx_11_0_arm64.whl (212 kB)\n",
      "Collecting protobuf~=3.19.5 (from pinecone-client[grpc])\n",
      "  Using cached protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/00/45/ec3407adf6f6b5bf867a4462b2b0af27597a26bd3cd6e2534cb6ab029938/filelock-3.12.2-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ftfy) (0.2.6)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Obtaining dependency information for pyarrow>=8.0.0 from https://files.pythonhosted.org/packages/a7/ca/a34c5dd3393644865b82ac5df66e52311fd4ae2fc073f62b68b8538a0da4/pyarrow-12.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached pyarrow-12.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Obtaining dependency information for dill<0.3.8,>=0.3.0 from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/8f/bb/aea1fbeed5b474cb8634364718abe9030d7cc7a30bf51f40bd494bbc89a2/pandas-2.0.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached pandas-2.0.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/ee/23/020ff3fa540e0d06886b6b866f1e173c554723e04f286ac205c5ddeb479e/xxhash-3.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached xxhash-3.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/e7/41/96ac938770ba6e7d5ae1d8c9cafebac54b413549042c6260f0d0a6ec6622/multiprocess-0.70.15-py311-none-any.whl.metadata\n",
      "  Using cached multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]>=2021.11.1 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]>=2021.11.1 from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/47/10/33abd984a476e314afdb4711fbd0aac1b25927676fa591445537da3aee98/aiohttp-3.8.5-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached aiohttp-3.8.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
      "  Obtaining dependency information for huggingface-hub<1.0.0,>=0.14.0 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Collecting gevent>=20.12.1 (from locust)\n",
      "  Obtaining dependency information for gevent>=20.12.1 from https://files.pythonhosted.org/packages/8a/f0/bcbf920572d0f1389b392a321e8c19be853f66f99ab43dfefa8374b46720/gevent-23.7.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Using cached gevent-23.7.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (13 kB)\n",
      "Collecting flask>=2.0.0 (from locust)\n",
      "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "Collecting Werkzeug>=2.0.0 (from locust)\n",
      "  Obtaining dependency information for Werkzeug>=2.0.0 from https://files.pythonhosted.org/packages/ba/d6/8040faecaba2feb84e1647af174b3243c9b90c163c7ea407820839931efe/Werkzeug-2.3.6-py3-none-any.whl.metadata\n",
      "  Using cached Werkzeug-2.3.6-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting msgpack>=0.6.2 (from locust)\n",
      "  Using cached msgpack-1.0.5-cp311-cp311-macosx_11_0_arm64.whl (69 kB)\n",
      "Requirement already satisfied: pyzmq!=23.0.0,>=22.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from locust) (25.1.0)\n",
      "Collecting geventhttpclient>=2.0.2 (from locust)\n",
      "  Using cached geventhttpclient-2.0.9-cp311-cp311-macosx_11_0_arm64.whl (42 kB)\n",
      "Collecting ConfigArgParse>=1.0 (from locust)\n",
      "  Obtaining dependency information for ConfigArgParse>=1.0 from https://files.pythonhosted.org/packages/6f/b3/b4ac838711fd74a2b4e6f746703cf9dd2cf5462d17dac07e349234e21b97/ConfigArgParse-1.7-py3-none-any.whl.metadata\n",
      "  Using cached ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: psutil>=5.6.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from locust) (5.9.5)\n",
      "Collecting Flask-BasicAuth>=0.2.0 (from locust)\n",
      "  Using cached Flask_BasicAuth-0.2.0-py3-none-any.whl\n",
      "Collecting Flask-Cors>=3.0.10 (from locust)\n",
      "  Obtaining dependency information for Flask-Cors>=3.0.10 from https://files.pythonhosted.org/packages/10/69/1e6cfb87117568a9de088c32d6258219e9d1ff7c131abf74249ef2031279/Flask_Cors-4.0.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached Flask_Cors-4.0.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting roundrobin>=0.0.2 (from locust)\n",
      "  Using cached roundrobin-0.0.4-py3-none-any.whl\n",
      "Collecting itsdangerous>=2.1.2 (from flask>=2.0.0->locust)\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.1.3 (from flask>=2.0.0->locust)\n",
      "  Obtaining dependency information for click>=8.1.3 from https://files.pythonhosted.org/packages/1a/70/e63223f8116931d365993d4a6b7ef653a4d920b41d03de7c59499962821f/click-8.1.6-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from flask>=2.0.0->locust)\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for charset-normalizer<4.0,>=2.0 from https://files.pythonhosted.org/packages/91/e6/8fa919fc84a106e9b04109de62bdf8526899e2754a64da66e1cd50ac1faa/charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.0.4-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.9.2-cp311-cp311-macosx_11_0_arm64.whl (61 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/9d/8b/8ab8143541b2c5fff4189fad7853e61d30e4ec4749ebf91e1d598c4e7c57/frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting zope.event (from gevent>=20.12.1->locust)\n",
      "  Obtaining dependency information for zope.event from https://files.pythonhosted.org/packages/fe/42/f8dbc2b9ad59e927940325a22d6d3931d630c3644dae7e2369ef5d9ba230/zope.event-5.0-py3-none-any.whl.metadata\n",
      "  Using cached zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting zope.interface (from gevent>=20.12.1->locust)\n",
      "  Using cached zope.interface-6.0-cp311-cp311-macosx_11_0_arm64.whl (202 kB)\n",
      "Collecting greenlet>=2.0.0 (from gevent>=20.12.1->locust)\n",
      "  Using cached greenlet-2.0.2-cp311-cp311-macosx_10_9_universal2.whl (243 kB)\n",
      "Collecting certifi (from geventhttpclient>=2.0.2->locust)\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from geventhttpclient>=2.0.2->locust) (1.16.0)\n",
      "Collecting brotli (from geventhttpclient>=2.0.2->locust)\n",
      "  Using cached Brotli-1.0.9-cp311-cp311-macosx_10_9_universal2.whl (806 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/fe/09/c31503cb8150cf688c1534a7135cc39bb9092f8e0e6369ec73494d16ee0e/MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Using cached MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.19.0->pinecone-client[grpc])\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->datasets)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from zope.event->gevent>=20.12.1->locust) (65.5.0)\n",
      "Using cached Pillow-10.0.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "Using cached regex-2023.6.3-cp311-cp311-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached datasets-2.14.3-py3-none-any.whl (519 kB)\n",
      "Using cached ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
      "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Using cached dnspython-2.4.1-py3-none-any.whl (300 kB)\n",
      "Using cached Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Using cached aiohttp-3.8.5-cp311-cp311-macosx_11_0_arm64.whl (339 kB)\n",
      "Using cached gevent-23.7.0-cp311-cp311-macosx_10_9_universal2.whl (3.0 MB)\n",
      "Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached grpcio-1.56.2-cp311-cp311-macosx_10_10_universal2.whl (8.9 MB)\n",
      "Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Downloading numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyarrow-12.0.1-cp311-cp311-macosx_11_0_arm64.whl (22.6 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Using cached multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "Using cached pandas-2.0.3-cp311-cp311-macosx_11_0_arm64.whl (10.7 MB)\n",
      "Using cached pinecone_client-2.2.2-py3-none-any.whl (179 kB)\n",
      "Using cached xxhash-3.3.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Using cached charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl (122 kB)\n",
      "Using cached click-8.1.6-py3-none-any.whl (97 kB)\n",
      "Using cached frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl (46 kB)\n",
      "Using cached MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl (17 kB)\n",
      "Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Using cached zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369498 sha256=5a0b934a1a1f0e82345f3971a7b408753f06e7f3c84818d221f38eafa610b8f7\n",
      "  Stored in directory: /private/var/folders/n7/j7krsnmx3wl7_bjrwhx2z7ym0000gn/T/pip-ephem-wheel-cache-j6iod03h/wheels/93/ad/0a/cc5888fd3998612d2e66d9d4f59add07818c8c12a23144cd76\n",
      "Successfully built clip\n",
      "Installing collected packages: roundrobin, pytz, msgpack, mpmath, brotli, zope.interface, zope.event, xxhash, urllib3, tzdata, typing-extensions, tqdm, sympy, regex, pyyaml, python-dotenv, protobuf, pillow, numpy, networkx, multidict, MarkupSafe, lz4, loguru, itsdangerous, idna, grpcio, greenlet, ftfy, fsspec, frozenlist, filelock, dnspython, dill, ConfigArgParse, click, charset-normalizer, certifi, blinker, attrs, async-timeout, yarl, Werkzeug, requests, pyarrow, pandas, multiprocess, jinja2, googleapis-common-protos, gevent, aiosignal, torch, pinecone-client, huggingface-hub, grpc-gateway-protoc-gen-openapiv2, geventhttpclient, flask, aiohttp, torchvision, Flask-Cors, Flask-BasicAuth, locust, datasets, clip\n",
      "Successfully installed ConfigArgParse-1.7 Flask-BasicAuth-0.2.0 Flask-Cors-4.0.0 MarkupSafe-2.1.3 Werkzeug-2.3.6 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 blinker-1.6.2 brotli-1.0.9 certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.6 clip-1.0 datasets-2.14.3 dill-0.3.7 dnspython-2.4.1 filelock-3.12.2 flask-2.3.2 frozenlist-1.4.0 fsspec-2023.6.0 ftfy-6.1.1 gevent-23.7.0 geventhttpclient-2.0.9 googleapis-common-protos-1.60.0 greenlet-2.0.2 grpc-gateway-protoc-gen-openapiv2-0.1.0 grpcio-1.56.2 huggingface-hub-0.16.4 idna-3.4 itsdangerous-2.1.2 jinja2-3.1.2 locust-2.15.1 loguru-0.7.0 lz4-4.3.2 mpmath-1.3.0 msgpack-1.0.5 multidict-6.0.4 multiprocess-0.70.15 networkx-3.1 numpy-1.25.2 pandas-2.0.3 pillow-10.0.0 pinecone-client-2.2.2 protobuf-3.19.6 pyarrow-12.0.1 python-dotenv-1.0.0 pytz-2023.3 pyyaml-6.0.1 regex-2023.6.3 requests-2.31.0 roundrobin-0.0.4 sympy-1.12 torch-2.0.1 torchvision-0.15.2 tqdm-4.65.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-2.0.4 xxhash-3.3.0 yarl-1.9.2 zope.event-5.0 zope.interface-6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"pinecone-client[grpc]\" \"python-dotenv\" \"torch\" \"torchvision\" \"pillow\" \"ftfy\" \"regex\" \"tqdm\" \"git+https://github.com/openai/clip.git\" \"datasets\" \"locust\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a pinecone index \n",
    "We will create an index that will be used to load/query a hugging face dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiException",
     "evalue": "(409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=UTF-8', 'date': 'Thu, 03 Aug 2023 22:37:10 GMT', 'x-envoy-upstream-service-time': '443', 'content-length': '35', 'server': 'envoy'})\nHTTP response body: index james-williams already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m INDEX_NAMESPACE \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mINDEX_NAMESPACE\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m pinecone\u001b[39m.\u001b[39minit(api_key\u001b[39m=\u001b[39mPINECONE_API_KEY, environment\u001b[39m=\u001b[39mPINECONE_ENVIRONMENT)\n\u001b[0;32m---> 15\u001b[0m pinecone\u001b[39m.\u001b[39;49mcreate_index(PINECONE_INDEX_NAME, dimension\u001b[39m=\u001b[39;49mDIMENSIONS, metric\u001b[39m=\u001b[39;49mMETRIC, pods\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, replicas\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, pod_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39ms1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     16\u001b[0m pinecone\u001b[39m.\u001b[39mdescribe_index(PINECONE_INDEX_NAME)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/manage.py:118\u001b[0m, in \u001b[0;36mcreate_index\u001b[0;34m(name, dimension, timeout, index_type, metric, replicas, shards, pods, pod_type, index_config, metadata_config, source_collection)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a Pinecone index.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[39m:param name: the name of the index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m:param timeout: Timeout for wait until index gets ready. If None, wait indefinitely; if >=0, time out after this many seconds; if -1, return immediately and do not wait. Default: None\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m api_instance \u001b[39m=\u001b[39m _get_api_instance()\n\u001b[0;32m--> 118\u001b[0m api_instance\u001b[39m.\u001b[39;49mcreate_index(create_request\u001b[39m=\u001b[39;49mCreateRequest(\n\u001b[1;32m    119\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    120\u001b[0m     dimension\u001b[39m=\u001b[39;49mdimension,\n\u001b[1;32m    121\u001b[0m     index_type\u001b[39m=\u001b[39;49mindex_type,\n\u001b[1;32m    122\u001b[0m     metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    123\u001b[0m     replicas\u001b[39m=\u001b[39;49mreplicas,\n\u001b[1;32m    124\u001b[0m     shards\u001b[39m=\u001b[39;49mshards,\n\u001b[1;32m    125\u001b[0m     pods\u001b[39m=\u001b[39;49mpods,\n\u001b[1;32m    126\u001b[0m     pod_type\u001b[39m=\u001b[39;49mpod_type,\n\u001b[1;32m    127\u001b[0m     index_config\u001b[39m=\u001b[39;49mindex_config \u001b[39mor\u001b[39;49;00m {},\n\u001b[1;32m    128\u001b[0m     metadata_config\u001b[39m=\u001b[39;49mmetadata_config,\n\u001b[1;32m    129\u001b[0m     source_collection\u001b[39m=\u001b[39;49msource_collection\n\u001b[1;32m    130\u001b[0m ))\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_ready\u001b[39m():\n\u001b[1;32m    133\u001b[0m     status \u001b[39m=\u001b[39m _get_status(name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/api_client.py:776\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    766\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    Example:\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m \n\u001b[1;32m    775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallable(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/api/index_operations_api.py:370\u001b[0m, in \u001b[0;36mIndexOperationsApi.__init__.<locals>.__create_index\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_check_return_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[1;32m    367\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m_check_return_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    368\u001b[0m )\n\u001b[1;32m    369\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_with_http_info(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/api_client.py:838\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m     header_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_client\u001b[39m.\u001b[39mselect_header_content_type(\n\u001b[1;32m    835\u001b[0m         content_type_headers_list)\n\u001b[1;32m    836\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m header_list\n\u001b[0;32m--> 838\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mcall_api(\n\u001b[1;32m    839\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mendpoint_path\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mhttp_method\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    840\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    841\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    842\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    843\u001b[0m     body\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    844\u001b[0m     post_params\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mform\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    845\u001b[0m     files\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    846\u001b[0m     response_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mresponse_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    847\u001b[0m     auth_settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mauth\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    848\u001b[0m     async_req\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39masync_req\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    849\u001b[0m     _check_type\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_check_return_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    850\u001b[0m     _return_http_data_only\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_return_http_data_only\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    851\u001b[0m     _preload_content\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_preload_content\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    852\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_request_timeout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    853\u001b[0m     _host\u001b[39m=\u001b[39;49m_host,\n\u001b[1;32m    854\u001b[0m     collection_formats\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mcollection_format\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/api_client.py:413\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__call_api(resource_path, method,\n\u001b[1;32m    414\u001b[0m                            path_params, query_params, header_params,\n\u001b[1;32m    415\u001b[0m                            body, post_params, files,\n\u001b[1;32m    416\u001b[0m                            response_type, auth_settings,\n\u001b[1;32m    417\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[1;32m    418\u001b[0m                            _preload_content, _request_timeout, _host,\n\u001b[1;32m    419\u001b[0m                            _check_type)\n\u001b[1;32m    421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    422\u001b[0m                                                method, path_params,\n\u001b[1;32m    423\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                                _request_timeout,\n\u001b[1;32m    432\u001b[0m                                                _host, _check_type))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/api_client.py:207\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_response \u001b[39m=\u001b[39m response_data\n\u001b[1;32m    211\u001b[0m return_data \u001b[39m=\u001b[39m response_data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/api_client.py:200\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    196\u001b[0m     url \u001b[39m=\u001b[39m _host \u001b[39m+\u001b[39m resource_path\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     response_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    201\u001b[0m         method, url, query_params\u001b[39m=\u001b[39;49mquery_params, headers\u001b[39m=\u001b[39;49mheader_params,\n\u001b[1;32m    202\u001b[0m         post_params\u001b[39m=\u001b[39;49mpost_params, body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    203\u001b[0m         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    204\u001b[0m         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout)\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/api_client.py:459\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mOPTIONS(url,\n\u001b[1;32m    452\u001b[0m                                     query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    453\u001b[0m                                     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m                                     _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    457\u001b[0m                                     body\u001b[39m=\u001b[39mbody)\n\u001b[1;32m    458\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mPOST(url,\n\u001b[1;32m    460\u001b[0m                                  query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    461\u001b[0m                                  headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    462\u001b[0m                                  post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[1;32m    463\u001b[0m                                  _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    464\u001b[0m                                  _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    465\u001b[0m                                  body\u001b[39m=\u001b[39;49mbody)\n\u001b[1;32m    466\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPUT\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mPUT(url,\n\u001b[1;32m    468\u001b[0m                                 query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    469\u001b[0m                                 headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                 _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    473\u001b[0m                                 body\u001b[39m=\u001b[39mbody)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/rest.py:271\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mPOST\u001b[39m(\u001b[39mself\u001b[39m, url, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, query_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, post_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    270\u001b[0m          body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _preload_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, _request_timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url,\n\u001b[1;32m    272\u001b[0m                         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    273\u001b[0m                         query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    274\u001b[0m                         post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[1;32m    275\u001b[0m                         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    276\u001b[0m                         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    277\u001b[0m                         body\u001b[39m=\u001b[39;49mbody)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/core/client/rest.py:230\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m500\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mstatus \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m599\u001b[39m:\n\u001b[1;32m    228\u001b[0m         \u001b[39mraise\u001b[39;00m ServiceException(http_resp\u001b[39m=\u001b[39mr)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mraise\u001b[39;00m ApiException(http_resp\u001b[39m=\u001b[39mr)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "\u001b[0;31mApiException\u001b[0m: (409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=UTF-8', 'date': 'Thu, 03 Aug 2023 22:37:10 GMT', 'x-envoy-upstream-service-time': '443', 'content-length': '35', 'server': 'envoy'})\nHTTP response body: index james-williams already exists\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pinecone\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "PINECONE_INDEX_NAME = os.environ['PINECONE_INDEX_NAME']\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
    "PINECONE_ENVIRONMENT = os.environ['PINECONE_ENVIRONMENT']\n",
    "METRIC = os.environ['METRIC']\n",
    "DIMENSIONS = int(os.environ['DIMENSIONS'])\n",
    "INDEX_NAMESPACE = os.environ['INDEX_NAMESPACE']\n",
    "\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
    "pinecone.create_index(PINECONE_INDEX_NAME, dimension=DIMENSIONS, metric=METRIC, pods=1, replicas=1, pod_type=\"s1\")\n",
    "pinecone.describe_index(PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load public image dataset(fashion-mnist) and create vector embeddings from the dataset\n",
    "\n",
    "Use the following shell command to download the [fashion-mnist](https://huggingface.co/datasets/fashion_mnist) training dataset from Hugging Face so that we can create vector embeddings that uses a label(image class) as meta-data from this dataset. The meta-data labels mappings are:\n",
    "\n",
    "| Label  | Description |\n",
    "| ------ | ----------- |\n",
    "| 0      | T-shirt/top |\n",
    "| 1      | Trouser     |\n",
    "| 2      | Pullover    |\n",
    "| 3      | Dress       |\n",
    "| 4      | Coat        |\n",
    "| 5      | Sandal      |\n",
    "| 6      | Shirt       |\n",
    "| 7      | Sneaker     |\n",
    "| 8      | Bag         |\n",
    "| 9      | Ankle boot  |\n",
    "\n",
    "The Fashion-MNIST dataset is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
    "\n",
    "The accuracy you can achieve depends on the model and the preprocessing steps you use. Here's a rough guideline for what you might expect with some classic machine learning algorithms:\n",
    "\n",
    "1. **Random Forest:** Around 85-89% accuracy.\n",
    "2. **Support Vector Machines (SVM):** Around 85-90% accuracy, depending on kernel and hyperparameters.\n",
    "3. **k-Nearest Neighbors (k-NN):** Around 85-88% accuracy.\n",
    "4. **Logistic Regression:** Around 82-85% accuracy.\n",
    "5. **Gradient Boosting Machines (e.g., XGBoost):** Around 87-90% accuracy.\n",
    "\n",
    "Keep in mind these numbers are approximate and can vary based on the exact preprocessing, feature extraction, and hyperparameter tuning you do. In general, deep learning models, especially Convolutional Neural Networks (CNNs), tend to perform better on image classification tasks like Fashion-MNIST, potentially reaching over 90-95% accuracy.\n",
    "\n",
    "But for classic machine learning models, anything in the 85-90% range can be considered a reasonable result for the Fashion-MNIST dataset. It reflects a model that has learned something meaningful from the data but isn't necessarily state-of-the-art for this particular task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Images: 100%|██████████| 6000/6000 [03:14<00:00, 30.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm  # progress bar\n",
    "from PIL import Image\n",
    "import torch\n",
    "import clip\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#  Load the fashion-mnist dataset - only retrieve 6000 random images (10% of total dataset)\n",
    "dataset = load_dataset(\"fashion_mnist\")['train'].shuffle(seed=42).select(range(0,6000))\n",
    "#dataset = load_dataset(\"fashion_mnist\")['train']\n",
    "\n",
    "label_descriptions = {0: \"T-shirt/top\", \n",
    "           1: \"Trouser\",\n",
    "           2: \"Pullover\",\n",
    "           3: \"Dress\",\n",
    "           4: \"Coat\",\n",
    "           5: \"Sandal\",\n",
    "           6: \"Shirt\",\n",
    "           7: \"Sneaker\",\n",
    "           8: \"Bag\",\n",
    "           9: \"Ankle boot\"}\n",
    "\n",
    "# Check to see if GPU is aviailable\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device=device)\n",
    "   \n",
    "# Generate vector embeddings for each image in the dataset\n",
    "id = 0\n",
    "vectors = []\n",
    "for img in tqdm(dataset, total=dataset.num_rows, desc='Images', position=0):\n",
    "    with torch.no_grad():\n",
    "        id += 1\n",
    "        image_pp = preprocess(img['image']).unsqueeze(0).to(device)\n",
    "        image_features = model.encode_image(image_pp)\n",
    "        embedding = image_features.cpu().numpy().squeeze().tolist()\n",
    "        meta_data = {\"description\": label_descriptions[img[\"label\"]], \"timestamp\": time.time()}\n",
    "        vectors.append({'id': str(id),\n",
    "                        'values': embedding,\n",
    "                        'metadata': meta_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create a local parquet backup of your image embeddings\n",
    "\n",
    "This is good practice because generating embeddings can be expensive and time consuming when calling hosted models like OpenAI. As you can see, even locally generated embeddings are time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "df = pd.DataFrame(vectors)\n",
    "df.to_parquet('fashion-mnist-clip.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Insert the fashion-mnist embeddings into Pinecone\n",
    "\n",
    "The best way to do bulk updates is by batching the dataset. We will also use a namespace for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60.0 [00:25<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm  # progress bar\n",
    "import pinecone\n",
    "import itertools\n",
    "\n",
    "# Read Parquet file into a DataFrame\n",
    "df = pd.read_parquet('fashion-mnist-clip.parquet')\n",
    "df['values'] = df['values'].apply(lambda x: x.tolist())\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "data_list = df.to_dict(orient='records')\n",
    "\n",
    "def chunks(iterable, batch_size=100):\n",
    "    \"\"\"A helper function to break an iterable into chunks of size batch_size.\"\"\"\n",
    "    it = iter(iterable)\n",
    "    chunk = tuple(itertools.islice(it, batch_size))\n",
    "    while chunk:\n",
    "        yield chunk\n",
    "        chunk = tuple(itertools.islice(it, batch_size))\n",
    "\n",
    "index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "# Obtain the upsert embeddings in batches of 100\n",
    "batch_size = 100\n",
    "id = 0\n",
    "for vector_batch in tqdm(chunks(data_list, batch_size=batch_size), total=(len(vectors) / batch_size)):\n",
    "   index.upsert(vector_batch, namespace=INDEX_NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Run a nearest neighbor search on a sample image that is not in the training dataset\n",
    "\n",
    "Download a sneaker image file from github that we will use to run a query to see if pinecone search returns the correct description \"Sneaker\". \n",
    "You can change the top_k from 1 to 10 to 100 to see how the ANN results vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from PIL import Image\n",
    "import torch\n",
    "import clip\n",
    "import requests\n",
    "\n",
    "# Check to see if GPU is aviailable\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device=device) \n",
    "\n",
    "def image_to_embedding():\n",
    "    \n",
    "    url = \"https://github.com/pinecone-io/basic-operations-workshop/blob/main/sneaker.jpeg?raw=true\"\n",
    "    response = requests.get(url)\n",
    "    with open(\"sneaker.jpeg\", \"wb\") as file:\n",
    "      file.write(response.content)\n",
    "    image_pp = preprocess(Image.open(\"./sneaker.jpeg\")).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "      embedding = model.encode_image(image_pp).squeeze().tolist()\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "top_k = 10\n",
    "\n",
    "query_result = index.query(\n",
    "  vector = image_to_embedding(),\n",
    "  namespace=INDEX_NAMESPACE,\n",
    "  top_k=top_k,\n",
    "  include_values=False,\n",
    "  include_metadata=True\n",
    ")\n",
    "\n",
    "top_k_contains = False\n",
    "match_cnt = 0\n",
    "miss_categories = set()\n",
    "\n",
    "for match in query_result.matches:\n",
    "  if match.metadata['description'] == \"Sneaker\":\n",
    "    match_cnt += 1\n",
    "    top_k_contains = True\n",
    "  else:\n",
    "    miss_categories.add(match.metadata['description'])\n",
    "\n",
    "print(f\"top_k contains matching result: {top_k_contains}\")\n",
    "print(f\"top_k: {top_k} match percentage is: {match_cnt/top_k * 100}%\")\n",
    "print(f\"Match miss categories: {miss_categories} exepected 'Sneaker'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Run a nearest neighbor search on 100 random test images that are not in the training dataset\n",
    "\n",
    "Select 100 random test images. Keep in mind the model was NOT trained against these images. Obtain the percentage of pinecone queries that return the correct result in top_k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import pinecone\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "test_dataset = load_dataset(\"fashion_mnist\")['test'].shuffle(seed=42).select(range(0, 100))\n",
    "\n",
    "# Check to see if GPU is aviailable\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device=device) \n",
    "\n",
    "# Generate vector embeddings for each image in the dataset\n",
    "test_vectors = []\n",
    "for img in tqdm(test_dataset, total=test_dataset.num_rows):\n",
    "  image_pp = preprocess(img['image']).unsqueeze(0).to(device)\n",
    "  embedding = model.encode_image(image_pp).squeeze().tolist()\n",
    "    \n",
    "  test_vectors.append({'embedding': embedding,\n",
    "                        'description': label_descriptions[img[\"label\"]]})\n",
    "    \n",
    "index = pinecone.Index(PINECONE_INDEX_NAME)\n",
    "top_k = 10\n",
    "top_k_contains_cnt = 0\n",
    "\n",
    "for v in test_vectors:\n",
    "\n",
    "  top_k_contains = False\n",
    "\n",
    "  query_result = index.query(\n",
    "    vector = v['embedding'],\n",
    "    namespace=INDEX_NAMESPACE,\n",
    "    top_k=top_k,\n",
    "    include_values=False,\n",
    "    include_metadata=True\n",
    "  )\n",
    "  \n",
    "  for match in query_result.matches:\n",
    "    if match.metadata['description'] == v['description']:\n",
    "      top_k_contains = True\n",
    "\n",
    "  if top_k_contains:\n",
    "    top_k_contains_cnt += 1\n",
    "\n",
    "print(f\"top_k contains matching result: {top_k_contains_cnt / (len(test_vectors)) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Run a load test script to simulate 10 concurrent users querying the index\n",
    "\n",
    "Locust.io is an open-source load testing tool written in Python. It allows you to define user behaviour with Python code and simulate millions of simultaneous users to bombard a system with traffic to test its resilience under heavy load. The (locustfile.py)[./locustfile.py] script re-uses the logic in step #6 to query pinecone. It has a custom event hook that denotes a failure if the top_k result set does not match the search image description. This script will likely fail with a low error rate but you can increase top_k to get a 100% pass rate. The locust summary includes P50 to P100 response time percentiles and QPS(req/s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "locust -f locustfile.py --headless -u 10 -r 1 --run-time 60s --host https://pinecone.io --only-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. TEARDOWN: Delete the index \n",
    "# WARNING: This next step will delete the PINECONE_INDEX_NAME index and all data in it. DO NOT RUN THIS UNTIL YOU ARE READY OR MANUALLY REMOVE THE INDEX INSTEAD!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PINECONE_INDEX_NAME in pinecone.list_indexes():\n",
    "    pinecone.delete_index(PINECONE_INDEX_NAME)\n",
    "    \n",
    "pinecone.list_indexes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
